
project:
  name: ev_load_fc
  seed: 42
  logging_level: 20 # 10=DEBUG, 20=INFO, 30=WARNING, 40=ERROR, 50=CRITICAL


paths:
  # Data paths
  raw_data: "datasets/01_raw"
  interim_data: "datasets/02_interim"
  processed_data: "datasets/03_processed"
  feature_store: "datasets/04_features"
  # Model paths
  exp_models: "models/experiments"
  prod_models: "models/production"
  # Other
  images: "images"
  logs: "logs"
  configs: "configs"


files:
  # Original raw data
  ev_filename: "ChargePoint Data CY20Q4.csv" 
  weather_filename: "WeatherEvents_Aug16_Dec20_Publish.csv"
  traffic_filename: "TrafficEvents_Aug16_Dec20_Publish.csv"
  # Interim
  ev_filt_filename: "ev_data_filt_date.csv"
  weather_filt_filename: "weather_data_filt_date_city.csv"
  temperature_filename: "temperature.csv"
  traffic_filt_filename: "traffic_data_filt_date_city.csv"
  # Processed
  ev_proc_filename: "ev_processed.csv"
  weather_proc_filename: "weather_processed.csv"
  temperature_proc_filename: "temperature_processed.csv"
  traffic_proc_filename: "traffic_processed.csv"
  combined_filename: "combined_processed.csv"
  

data:

  # Filters to apply to raw datasets when importing
  raw_filters:
    # Define the time period our data will be contained in
    min_timestamp: "2017-08-01"       
    max_timestamp: "2020-03-01" 
    # Cities to filter the raw LSTW weather data by        
    weather_cities:
      - "Palo Alto"
      - "Mountain View"
      - "San Carlos"
    # Weather stations to filter meteostat data by
    meteostat_staions:
      - "KPAO0"
      - "74509"
      - "KSQL0"
    # Cities to filter the raw LSTW traffic data by     
    traffic_cities:
      - "Palo Alto"
      - "East Palo Alto"
      - "Menlo Park"
      - "Stanford"
      - "Atherton"
      - "Mountain View"
      - "Los Altos"

  # Parameters to apply to the imported raw datasets during preprocessing
  preprocessing:
    # Miscelaneous
    sampling_interval: "1h"
    plug_power_quantile_bound: 0.001 # Decimal value defining what upper and lower quantiles (as cutoffs) to define for estimated plug charging power in the EV datasets 
                                     # e.g. 0.001 means we restrict the EV dataset to be between the 0.1% and 99.9% quantiles for plug power
    mad_thresholds: 3.5
    split_date: "2019-08-01" # Cutoff date between train and test samples
    min_outlier_samples: 720 # When computing parameters to detect outliers using a rolling MAD method, 
                             # This value defines from which point we will start detecting outliers in the train set (see ev_load_fc.data.preprocessing.rolling_mad_outliers) 
    # Columns of the raw EV dataset necessary for preprocessing
    ev_keep_cols:
      - "starttime"
      - "endtime"
      - "energy"
      - "charging_time"
      - "plug_type"
      - "duration_hours"
      - "charger_kw"
    # Columns of the raw LSTW weather dataset necessary for preprocessing
    weather_keep_cols:
      - "starttime"
      - "endtime"
      - "type"
      - "severity"
      - "duration"
    # Types of weather event to filter the LSTW weather dataset by
    weather_type_filt:
      - "Rain"
      - "Fog"
      - "Storm"
    # Columns of the raw LSTW taffic dataset necessary for preprocessing
    traffic_keep_cols:
      - "starttime"
      - "endtime"
      - "type"
      - "severity"
      - "distance"
      - "duration"
    # Types of traffic event to filter the LSTW weather dataset by
    traffic_type_filt:
      - "Congestion"
      - "Flow-Incident"
      - "Event"


features:

  # Target column
  target: 'energy'

  # Parameters for the creation of exogenous features
  feature_engineering:
    # Calender holidays to create one-hot-encodings of
    holidays:
      - "Independence Day"
      - "Thanksgiving Day"
      - "Christmas Eve"
      - "Christmas Day"
      - "Boxing Day"
      - "New Year's Day"
    # Lists of substrings used to find a subset of exogenous columns to create lag/rolling window based features from
    energy_col_substrs: ['energy']
    weather_col_substrs: ['fog_dur','rain_dur','storm_dur']
    temperature_col_substrs: ['temp']
    traffic_col_substrs: ['cong_dur','cong_dis','flow_dur','flow_dis','event_dur','event_dis']
    # Define lag/rolling window sizes for each of energy , weather , temperature and traffic data
    time_feature_dict:
      lags: 
        energy: [1,3,6,24,168]
      rolling_sums: 
        energy: [3,6,12,24,168]
        weather: [1,3,6]
        traffic: [1,3,6]
      rolling_means: 
        energy: [3,6,12,24,168]
        temperature: [1,3,6,12]

  # Feature selection to create training set
  feature_selection:
    scale_method: ""
    k_1: 30            # Number of features to select in first round of feature elimination
    fe_method_1: "f"   # Method to select K best features from X_train - 'f', 'mi', 'imp', 'rfe', 'rfecv'
    k_2: 20            # Number of features to select in second round of feature elimination (must have k_1 >= k_2)
    fe_method_2: "rfe" # Method to select K best features from X_train - 'f', 'mi', 'imp', 'rfe', 'rfecv'
    correlation_threshold: 1.0
  
training:

  feature_version: "f_30_rfe_20" # Select version of data based on feature selection method
                                 # Use format "{fe_method_1}_{k_1}_{fe_method_2}_{k_2}"

  mlflow:
    tracking_uri: "http://127.0.0.1:5000/"
    experiment_name: "Tree Based Models"

  optuna:
    verbosity: 30 # 10=DEBUG, 20=INFO, 30=WARNING, 40=ERROR, 50=CRITICAL
    models_to_run: ["Random Forest"] # List of models to train using Optuna studies
                                     # Choose from: "Random Forest" "AdaBoost" "XGBoost" "LightGBM" "CatBoost" "Prophet"
    trials: 250 # How many trials each Optuna study should have 
    metric: "rsme" # Evaluation metric used in Optuna trials, choose from: 
    splits: 4 # Number of splits for time series cross-validation

    search_spaces:
      Random Forest:
        n_estimators : [50,500]
        max_depth : [6,36]
        min_samples_split : [5,50]
        min_samples_leaf : [5,100]
        max_leaf_nodes : [20,60]
        max_features : ['sqrt']
        n_jobs : [-1]
      AdaBoost:
        n_estimators: [50,500]
        learning_rate : [0.01,0.1]
        loss : ['linear','square','exponential']
      

    